Оптимизация данных в полях типа BLOB
====================================

Это экспериментальный проект по оптимизации данных в полях типа BLOB СУБД Firebird.

В Firebird BLOB-ы могут быть двух типов: сегментированные (segmented) и потоковые (stream).

## Сегментированные BLOB

Единицей хранения сегментированных BLOB является сегмент. Сегмент это порция данных которой был записан BLOB. 
В таких BLOB-ах дополнительно хранятся границы сегментов. Максимальный размер сегмента составляет 65535 Байт.

Сегменты могут быть разного размера, например если вы записываете 80 Кбайт данных, то такой BLOB может содержать два сегмента 50Кбайт и 30КБайт, или три 30КБайт, 30КБайт и 20 КБайт, или любое другое количество и размер сегментов. Всё зависит от того какими порциями вы записывали BLOB.

Важно! Необязательное предложение `SEGMENT SIZE` которое указывается при объявлении BLOB полей, никак не влияет на размер сегментов, только если приложение не использует эти сведения из метаданных, для определения размера сегментов которыми должен быть записан BLOB.

При чтении сегментированных BLOB, за один API вызов `isc_get_segment` (`IBlob::getSegment`) будет прочитано указанное количество байт, но не более чем размер сегмента, который был записан. Таким образом, даже если вы пытаетесь прочесть 1 Мбайт BLOB
порциями по 65535 Байт, но который был записан сегментами по 1 Кбайт, то вы вам потребуется 1024 (1 Мбайт / 1 Кбайт) вызова `isc_get_segment`, чтобы прочитать такой BLOB целиком. 

Сегментированные BLOB хорошо подходят для хранения структур данных фиксированного размера. Однако при хранении 
данных вроде произвольного текста или изображений возникают дополнительные издержки из-за хранения границ сегментов.
Кроме того, дополнительные издержки могут возникнуть при чтении сегментированных BLOB, если они записаны сегментами 
маленького размера. Отсюда совет: если вы не сохраняете структуры фиксированного размера, всегда пишите BLOB максимальным размером сегмента. Если необходимо сохранять структуры фиксированного размера, то пишите BLOB сегментами размерами этой структуры, это упростит их считывание.

Агрегатная функция LIST всегда создаёт временный сегментированный BLOB с сегментами размером равными суммарному размеру аргументов, если конечно вы не объединяете BLOB-ы.

## Потоковые BLOB

Потоковые BLOB представляют собой просто поток байтов. В отличие от сегментированных BLOB они не сохраняют размер порций, которыми были записаны. Это обозначает что вы можете считывать такие BLOB любыми порциями, не зависимо от того какими порциями вы записывали их. То есть если вы записали 1 МБайт BLOB порциями по 1 КБайт, а читаете порциями по 50 КБайт, то вам потребуется приблизительно 20 (1 Мбайт / 50 Кбайт) вызовов `isc_get_segment`, чтобы прочитать такой BLOB целиком.

Потоковые BLOB имеют ещё одно преимущество перед сегментированными — они поддерживают позиционирование с помощью функции
`isc_seek_blob` (`IBLOB::seek`). Однако учтите, что такое позиционирование работает только для BLOB размер которых не превышает 2 ГБайт.

## Возможные проблемы приложений при работе с сегментированными BLOB

Некоторые приложения написаны так что они записывают поля типа BLOB сегментами с небольшим размером.
Есть случаи компоненты доступа ориентируются на метаданные, где зачастую записано что-то вроде

```sql
PIC  BLOB SUB_TYPE 0 SEGMENT SIZE 80
```

В таком случае такие компоненты доступа могут записывать сегментами по 80 байт. Это может негативно отразиться на скорости чтения таких BLOB полей клиентским приложением.

## Описание утилиты blob_opt

Утилита `blob_opt` позволяет читать данные из таких BLOB полей и 

* перезаписывать их с заданны размером сегмента. Обычно чем больше такой размер тем лучше;
* преобразовывать BLOB поля в потоковые BLOB.

В файле `select.sql` расположен запрос который читает данные из искомой таблицы. Этот запрос должен выбирать два поля: поле первичного ключа и поле типа BLOB. Если в таблице нет первичного ключа или он является составным, то вы можете воспользоваться служебным полем `RDB$DB_KEY`.

Пример содержимого файла `select.sql`:

```sql
select 
  id,
  pic
from t
where pic is not null
```

Вы можете использовать любые фильтры которые ограничат размер выборки. Например, можно использовать функцию OCTETS_LENGTH для отсечки совсем маленьких BLOB.

В файле `modify.sql` расположен модифицирующий запрос, т.е. запрос который пишет содержимое нового BLOB обратно в базу данных.


***
*Важно*

Имена параметров в запросе должны совпадать с именами полей из запроса в `select.sql`.
***

Пример содержимого файла `modify.sql`:

```sql
update t
set pic = :pic
where id = :id
```

Настройки сохраняются в файле `settings.json`.

Исполняемый файл можно скачать по ссылке [blob_optimize.exe](https://github.com/sim1984/blob_opt/releases/download/1.0/blob_optimize.exe)

Примеры файлов с запросами:

* [select.sql](https://github.com/sim1984/blob_opt/releases/download/1.0/select.sql)
* [modify.sql](https://github.com/sim1984/blob_opt/releases/download/1.0/modify.sql)

***
*Важно*

Требуется установленная 64-разрядная библиотека `fbclient.dll`. 
Если библиотека не установлена, то поместите её в каталог с исполняемым файлом.
***
